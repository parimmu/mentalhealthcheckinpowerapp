{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parimmu/mentalhealthcheckinpowerapp/blob/master/cse_163_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UWsBYgNxzjRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Factors that Affect Students’ Grades and Performance**\n"
      ],
      "metadata": {
        "id": "XkN4ycrQhp7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Motivation**\n",
        "In the process of learning, many students will encounter the problem of unstable grades or inefficient learning methods. Understanding which factors affect achievement will not only help us better target learning methods, but also enable teachers and parents to provide better support. Moreover, when the overall academic level of students is improved, the overall educational level will also be correspondingly improved, which will help cultivate more talents and promote the progress of society.\n"
      ],
      "metadata": {
        "id": "xxIBm1AciFsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Setting**\n",
        "For this project, using three publicly available datasets from Kaggle, each containing information about students’ demographic characteristics, learning behaviors, and academic performance. These datasets provide a comprehensive view of the factors that may affect students’ final grades, making them suitable for building a predictive model and exploring relationships between different variables.\n",
        "The titles and links that use in this project are listed below:\n",
        "\n",
        "Student Final Grade Prediction - Multi Linear Regression https://www.kaggle.com/datasets/rabieelkharoua/students-performance-dataset/data\n",
        "\n",
        "Student Performance Data Set https://www.kaggle.com/datasets/joebeachcapital/students-performance/data\n",
        "\n",
        "Student Performance Data Set https://www.kaggle.com/datasets/mariazhokhova/higher-education-students-performance-evaluation\n"
      ],
      "metadata": {
        "id": "NCb9_ovkzn9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qi8EiEWmy9Bo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Challenge Goals**\n",
        "\n",
        "1. Multiple Datasets:\n",
        "Using three datasets: Student Final Grade Prediction - Multi Linear Regression, Student Performance Data Set, and Students Performance Dataset. These datasets are merged using Pandas’ pd.merge() function, combining them based on shared features such as gender, age, and parental education level.\n",
        "This operation allows us to create a comprehensive dataset that includes variables from all three sources. At least two research questions involve multiple datasets. For example, comparing the academic performance of students from different demographic groups using variables from all three datasets. Additionally, we explore whether students’ average scores are influenced by their parental education level and study time, using data from the merged datasets.\n",
        "\n",
        "2. Machine Learning :\n",
        "Applying three machine learning algorithms from Scikit-learn: Linear Regression, Decision Tree Regression, and Random Forest Regression. For example, for Decision Tree Regression, adjusting the maximum depth (max_depth) and minimum samples split (min_samples_split). Also, we will use a Linear Regression model to predict student average grades, then use Pandas and Scikit-learn libraries to process the data, train the model, and use predict() to make predictions, and use MAE, MSE, and R² to evaluate model performance.\n"
      ],
      "metadata": {
        "id": "dGwRd3gMfKU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Methods**\n",
        "**Data Loading & Cleaning & Preprocessing: **\n",
        "Three data sets are imported and the data is initially processed to ensure that it is clean and suitable for subsequent analysis.Steps: Import three datasets using pandas.read_csv(). Use df.describe() to view the data overview. Delete missing values (dropna()) or fill them with the mean (fillna()). Use df.drop() to drop columns that are not relevant to the study.\n",
        "\n",
        "**Understand data distribution and characteristics:**\n",
        "Understand data distribution, relationships between features, and factors that may affect student achievement. Steps: Use df.describe() and df.value_counts() to view the data distribution. Use groupby() to average grades by different variables (e.g., gender, race/ethnicity, parental education level)\n",
        "\n",
        "**Data Visualization:**\n",
        "Use graphs to visualize the distribution of achievement, the differences between different groups, and the relationships between variables. Steps: Create charts using Matplotlib and Seaborn. For example, boxplot(sns.boxplot()) : compare achievement differences by gender and race. scatterplot(sns.scatterplot()) : shows the relationship between learning time, parental education level, and achievement.\n",
        "\n",
        "**Machine Learning & Model Training:**\n",
        "Use machine learning models to predict students’ grades based on their personal characteristics and study habits. ​​Use Linear Regression, Decision Tree Regression, and Random Forest Regression from Scikit-learn.Train each model using study time, parental education level, and others as features, and predict the average score.Use train_test_split() to divide the data into training and testing sets.\n",
        "\n",
        "**Model Performance Evaluation:**\n",
        "Compare the performance of different machine learning models to determine which one provides the most accurate predictions. ​​Calculate MAE, MSE, and R² for each model. Visualize the predictions using scatterplot() to compare actual and predicted scores.\n"
      ],
      "metadata": {
        "id": "PZGt5td1z5rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.linear_model import LinearRegression\n",
        "#from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Read the CSV files\n",
        "def load_and_clean_data():\n",
        "  \"\"\"\n",
        "  Loads three CSV files containing student performance data, drops rows with missing values\n",
        "  and standardizes column names across the datasets.\n",
        "  Rename columns related to final grades, parental education, gender, age, and student ID to ensure consistency for merging and analysis.\n",
        "  Returns three cleaned DataFrames for further processing.\n",
        "  \"\"\"\n",
        "  df1 = pd.read_csv(\"/content/drive/My Drive/CSE163_project/Student_performance_data_.csv\")\n",
        "  df2 = pd.read_csv(\"/content/drive/My Drive/CSE163_project/StudentsPerformance_with_headers.csv\")\n",
        "  df3 = pd.read_csv(\"/content/Student performance data/DATA.csv\", delimiter=\";\")\n",
        "\n",
        "  df1 = df1.dropna()\n",
        "  df2 = df2.dropna()\n",
        "  df3 = df3.dropna()\n",
        "\n",
        "  df1[\"final_score\"] = df1[\"GPA\"]\n",
        "  df2[\"final_score\"] = df2[\"Cumulative grade point average in the last semester (/4.00)\"]\n",
        "  df3[\"final_score\"] = df3[\"grade_previous\"]\n",
        "\n",
        "  df1[\"parental_education\"] = df1[\"ParentalEducation\"]\n",
        "  df2[\"parental_education\"] = df2[[\"Mother’s education\", 'Father’s education ']].max(axis=1)\n",
        "  df3[\"parental_education\"] = df3[[\"mother_ed\", \"farther_ed\"]].max(axis=1)\n",
        "\n",
        "  df1 = df1.rename(columns={\"Gender\": \"sex\"})\n",
        "  df1 = df1.rename(columns={\"Age\": \"Student Age\"})\n",
        "  df1 = df1.rename(columns={\"StudentID\": \"student_id\"})\n",
        "  df2 = df2.rename(columns={\"STUDENT ID\": \"student_id\"})\n",
        "  df2 = df2.rename(columns={\"Sex\": \"sex\"})\n",
        "  df3 = df3.rename(columns={\"age\": \"Student Age\"})\n",
        "  return df1, df2, df3\n",
        "\n",
        "\n",
        "def categorize_study_time(hours):\n",
        "    \"\"\"\n",
        "    Categorizes weekly study hours into five groups based on their value.\n",
        "    Takes an integer representing study hours\n",
        "    Returns a category from 1 to 5, where 1 is 0 hours, 2 is less than 5, 3 is less than 10\n",
        "    4 is less than 20, and 5 is 20 or more hours.\n",
        "    \"\"\"\n",
        "    if hours == 0:\n",
        "        return 1\n",
        "    elif hours < 5:\n",
        "        return 2\n",
        "    elif hours < 10:\n",
        "        return 3\n",
        "    elif hours < 20:\n",
        "        return 4\n",
        "    else:\n",
        "        return 5\n",
        "\n",
        "def process_study_time(df1, df2, df3):\n",
        "    \"\"\"\n",
        "    In this function, it takes df1, df2 and df3 as arguments\n",
        "    Standardizes study time data across three datasets by mapping weekly study hours into consistent group labels.\n",
        "    Applies the categorize_study_time function to one dataset and maps predefined group labels to the others.\n",
        "    Returns the three updated DataFrames with a new 'study_time_group' column for each.\n",
        "    \"\"\"\n",
        "    df1[\"study_time\"] = df1[\"StudyTimeWeekly\"].apply(categorize_study_time)\n",
        "    df1[\"study_time_group\"] = df1[\"study_time\"].map({\n",
        "        1: \"0h\", 2: \"<5h\", 3: \"6~10h\", 4: \"11~20h\", 5: \"20+h\"\n",
        "    })\n",
        "\n",
        "    df2[\"study_time_group\"] = df2[\"Weekly study hours\"].map({\n",
        "        1: \"0h\", 2: \"<5h\", 3: \"6~10h\", 4: \"11~20h\", 5: \"20+h\"\n",
        "    })\n",
        "\n",
        "    df3[\"study_time_group\"] = df3[\"weekly_study_hours\"].map({\n",
        "        1: \"0h\", 2: \"<5h\", 3: \"6~10h\", 4: \"11~20h\", 5: \"20+h\"\n",
        "    })\n",
        "\n",
        "    return df1, df2, df3\n",
        "#I used google search to unify these three data sets by map method, so that it can be easily read.\n",
        "\n",
        "\n",
        "def merge_datasets(df1, df2, df3):\n",
        "    \"\"\"\n",
        "    In this function, it takes df1, df2 and df3 as arguments\n",
        "    Merges three standardized datasets into one DataFrame by combining common columns, including sex, age, final score,\n",
        "    parental education, and study time group. Performs an outer join to ensure all records are included,\n",
        "    and returns the merged DataFrame.\n",
        "    \"\"\"\n",
        "    common_columns = [\"sex\", \"Student Age\", \"final_score\", \"parental_education\", \"study_time_group\"]\n",
        "    merged_df = pd.merge(df1[common_columns], df2[common_columns], how=\"outer\")\n",
        "    merged_df = pd.merge(merged_df, df3[common_columns], how=\"outer\")\n",
        "    return merged_df\n",
        "\n",
        "def test_merge_datasets():\n",
        "    df1 = pd.DataFrame({\n",
        "        'sex': ['M'],\n",
        "        'Student Age': [18],\n",
        "        'final_score': [3.5],\n",
        "        'parental_education': [4],\n",
        "        'study_time_group': ['<5h']\n",
        "    })\n",
        "\n",
        "    df2 = pd.DataFrame({\n",
        "        'sex': ['F'],\n",
        "        'Student Age': [19],\n",
        "        'final_score': [3.0],\n",
        "        'parental_education': [3],\n",
        "        'study_time_group': ['6~10h']\n",
        "    })\n",
        "\n",
        "    df3 = pd.DataFrame({\n",
        "        'sex': ['M'],\n",
        "        'Student Age': [20],\n",
        "        'final_score': [2.5],\n",
        "        'parental_education': [2],\n",
        "        'study_time_group': ['11~20h']\n",
        "    })\n",
        "\n",
        "    merged = merge_datasets(df1, df2, df3)\n",
        "    expected_columns = ['sex', 'Student Age', 'final_score', 'parental_education', 'study_time_group']\n",
        "    assert list(merged.columns) == expected_columns\n",
        "\n",
        "def group_by_analysis(merged_df):\n",
        "    \"\"\"\n",
        "    In this function, it takes merfed_df as argument.\n",
        "    Calculates the mean final score by gender, parental education, and study time group.\n",
        "    Returns three groupings with their corresponding average scores to compare performance across these factors.\n",
        "    \"\"\"\n",
        "    gender_group = merged_df.groupby(\"sex\")[\"final_score\"].mean()\n",
        "    parent_group = merged_df.groupby(\"parental_education\")[\"final_score\"].mean()\n",
        "    study_time_group = merged_df.groupby(\"study_time_group\")[\"final_score\"].mean()\n",
        "    return gender_group, parent_group, study_time_group\n",
        "\n",
        "def test_group_by_analysis():\n",
        "  df = pd.DataFrame({\n",
        "      'sex': ['M', 'F'],\n",
        "      'parental_education': [4, 4],\n",
        "      'study_time_group': ['<5h', '6~10h'],\n",
        "      'final_score': [3.0, 4.0]\n",
        "  })\n",
        "\n",
        "  gender_group, parent_group, study_group = group_by_analysis(df)\n",
        "\n",
        "  assert gender_group['M'] == 3.0\n",
        "  assert gender_group['F'] == 4.0\n",
        "  assert parent_group[4] == 3.5\n",
        "  assert study_group['<5h'] == 3.0\n",
        "\n",
        "\n",
        "def generate_statistics(merged_df):\n",
        "    \"\"\"\n",
        "    In this function, it takes merfed_df as argument.\n",
        "    Generates basic descriptive statistics and counts for the merged dataset, including summaries for sex,\n",
        "    parental education, and study time groups.\n",
        "    Returns the descriptive statistics and counts for further interpretation.\n",
        "    \"\"\"\n",
        "    data_description = merged_df.describe()\n",
        "    value_counts_gender = merged_df[\"sex\"].value_counts()\n",
        "    value_counts_parent_edu = merged_df[\"parental_education\"].value_counts()\n",
        "    value_counts_study_time = merged_df[\"study_time_group\"].value_counts()\n",
        "    return data_description, value_counts_gender, value_counts_parent_edu, value_counts_study_time\n",
        "\n",
        "def test_generate_statistics():\n",
        "    df = pd.DataFrame({\n",
        "        'sex': ['M', 'F', 'F'],\n",
        "        'parental_education': [3, 4, 4],\n",
        "        'study_time_group': ['<5h', '6~10h', '6~10h'],\n",
        "        'final_score': [2.5, 3.5, 4.0]\n",
        "    })\n",
        "\n",
        "    desc, gender_counts, parent_counts, study_counts = generate_statistics(df)\n",
        "    assert gender_counts['F'] == 2\n",
        "    assert gender_counts['M'] == 1\n",
        "    assert parent_counts[4] == 2\n",
        "    assert parent_counts[3] == 1\n",
        "    assert study_counts['6~10h'] == 2\n",
        "    assert study_counts['<5h'] == 1\n",
        "\n",
        "def standardize_columns(df1, df2, df3, merged_df):\n",
        "    \"\"\"\n",
        "    In this function, it takes df1, df2, df3 and merged_df as arguments.\n",
        "    Converts the parental education column to Int64 type across all datasets and the merged DataFrame.\n",
        "    Standardizes the gender column in the merged DataFrame by mapping 'Male' to 1, 'Male' to 2 and 'Female' to 0,\n",
        "    and converts parental education to categorical type for grouped analysis.\n",
        "    Returns the updated datasets and merged DataFrame.\n",
        "    \"\"\"\n",
        "  # making sure that 'parental_education' is consistent in all datasets\n",
        "    df1[\"parental_education\"] = df1[\"parental_education\"].astype(float).astype(\"Int64\")\n",
        "    df2[\"parental_education\"] = df2[\"parental_education\"].astype(float).astype(\"Int64\")\n",
        "    df3[\"parental_education\"] = df3[\"parental_education\"].astype(float).astype(\"Int64\")\n",
        "\n",
        "  # Convert 'parental_education' to a consistent data type\n",
        "    merged_df[\"parental_education\"] = merged_df[\"parental_education\"].astype(float).astype(\"Int64\")\n",
        "\n",
        "  # Convert categorical gender labels\n",
        "    if \"sex\" in merged_df.columns:\n",
        "        merged_df[\"sex\"] = merged_df[\"sex\"].replace({1: \"Male\", 0: \"Female\", 2: \"Male\"})  # Standardizing gender labels\n",
        "\n",
        "  # Convert parental education into categorical to ensure correct ordering\n",
        "    merged_df[\"parental_education\"] = merged_df[\"parental_education\"].astype(\"category\")\n",
        "    return df1, df2, df3, merged_df\n",
        "\n",
        "def filter_study_time_groups(merged_df):\n",
        "    \"\"\"\n",
        "    In this function, it takes merfed_df as argument.\n",
        "    Filters out study time groups with fewer than six observations to improve analysis reliability.\n",
        "    Returns the filtered DataFrame with only groups that have more than five records.\n",
        "    \"\"\"\n",
        "  # Check the number of students in each study time group\n",
        "    study_time_counts = merged_df[\"study_time_group\"].value_counts()\n",
        "\n",
        "  # Filter out study time groups with very few observations\n",
        "    filtered_df = merged_df[merged_df[\"study_time_group\"].isin(study_time_counts[study_time_counts > 5].index)]\n",
        "    return filtered_df\n",
        "  #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html\n",
        "  #filter DataFrame values by checking if elements exist in a given list or another iterable\n",
        "def plot_graphs(filtered_df):\n",
        "    \"\"\"\n",
        "    In this function, it takes filtered_df as argument.\n",
        "    Creates multiple visualizations to compare final scores by gender, parental education, and study time groups by using\n",
        "    boxplots, scatterplots, and lineplots.\n",
        "    Uses Seaborn and Matplotlib to display relationships between these variables and outputs the plots for interpretation.\n",
        "    \"\"\"\n",
        "    # Boxplot: Achievement differences by gender\n",
        "    \"\"\"\n",
        "    The boxplot comparing final scores by gender shows no significant difference between male and female students.\n",
        "    The distribution of scores is similar across both groups, suggesting that gender does not play a major role in\n",
        "    academic performance. The median scores are nearly identical, with slight variations in spread, indicating that\n",
        "    factors beyond gender are more influential in determining student success.\n",
        "\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.boxplot(x=\"sex\", y=\"final_score\", data=filtered_df)\n",
        "    plt.title(\"Achievement Differences by Gender\")\n",
        "    plt.xlabel(\"Gender\")\n",
        "    plt.ylabel(\"Final Score\")\n",
        "    plt.show()\n",
        "\n",
        "    # Boxplot: Achievement differences by parental education level\n",
        "    \"\"\"\n",
        "    Students with higher parental education levels tend to have slightly higher final scores,\n",
        "    but the effect is not strongly linear. While the median scores increase slightly with higher\n",
        "    parental education, the spread of scores suggests high variability within each group.\n",
        "    This indicates that parental education may contribute to academic performance but is not the sole\n",
        "    determining factor—other influences such as school environment, personal motivation, and support systems likely play a role.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(x=\"parental_education\", y=\"final_score\", data=filtered_df)\n",
        "    plt.title(\"Achievement Differences by Parental Education Level\")\n",
        "    plt.xlabel(\"Parental Education Level\")\n",
        "    plt.ylabel(\"Final Score\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "    # Scatterplot: Relationship between study time, parental education level, and achievement\n",
        "    \"\"\"\n",
        "    Replacing the scatter plot with a bar chart makes the relationship between study time,\n",
        "    parental education, and final scores clearer. The chart shows that students who study\n",
        "    more tend to have slightly higher scores, but the difference is not drastic. Additionally,\n",
        "    the impact of study time varies across different parental education levels, reinforcing the\n",
        "    idea that study habits alone do not guarantee success. Other contributing factors such as\n",
        "    teaching quality, learning strategies, and personal discipline likely shape academic outcomes.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x=\"parental_education\", y=\"final_score\", hue=\"study_time_group\", data=filtered_df, alpha=0.7)\n",
        "    plt.title(\"Relationship Between Parental Education, Study Time, and Achievement\")\n",
        "    plt.xlabel(\"Parental Education Level\")\n",
        "    plt.ylabel(\"Final Score\")\n",
        "    plt.legend(title=\"Study Time Group\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "    # Updated Line Plot with Compatible Confidence Interval Setting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.lineplot(\n",
        "        data=filtered_df,\n",
        "        x=\"parental_education\",\n",
        "        y=\"final_score\",\n",
        "        hue=\"study_time_group\"\n",
        "    )\n",
        "    plt.title(\"Improved Interaction Between Study Time and Parental Education on Final Grades\")\n",
        "    plt.xlabel(\"Parental Education Level\")\n",
        "    plt.ylabel(\"Final Score\")\n",
        "    plt.legend(title=\"Study Time Group\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "    df1, df2, df3 = load_and_clean_data()\n",
        "    df1, df2, df3 = process_study_time(df1, df2, df3)\n",
        "    merged_df = merge_datasets(df1, df2, df3)\n",
        "    df1, df2, df3, merged_df = standardize_columns(df1, df2, df3, merged_df)\n",
        "    filtered_df = filter_study_time_groups(merged_df)\n",
        "    plot_graphs(filtered_df)\n",
        "\n",
        "def preprocess_data(merged_df):\n",
        "  \"\"\"\n",
        "  This function encodes categorical variales and splits the dataset into training and testing sets.\n",
        "  With parameter merged_def(DataFrame), the cleaned and merged dataset containing student performance data.\n",
        "  returns training and testing sets for features and target variables\n",
        "  \"\"\"\n",
        "  features = [\"study_time\", \"parental_education\", \"sex\", \"Student Age\"]\n",
        "  X = pd.get_dummies(merged_df[features], drop_first = True)\n",
        "  y =  merged_df[\"final_score\"]\n",
        "\n",
        "  #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "  return train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "def train_and_evaluate_models(X_train, X_test, y_train, y_test):\n",
        "  \"\"\"\n",
        "  This function trains and evalautes machine learning models\n",
        "  With parameters:\n",
        "  X_train, X_test, y_train, y_test - training and testing sets\n",
        "  returns:\n",
        "  models (dict): Dictionary of trained models\n",
        "  results (dict): Model performance metrics(Mean Squared Error)\n",
        "  \"\"\"\n",
        "  models = {\n",
        "      #\"Linear Regression\": LinearRegression(),\n",
        "      #\"Decision Tree\": DecisionTreeRegressor(max_depth = 5, min_samples_split=5)\n",
        "      \"Random Forest\": RandomForestRegressor(n_estimators = 100, random_state = 42),\n",
        "      \"Support Vector Regression\": SVR(kernel = \"linear\")\n",
        "  }\n",
        "\n",
        "  result = {}\n",
        "  trained_models = {}\n",
        "\n",
        "  for model_name, model in models.items():\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    #making predctions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    result[model_name] = {\"MAE\": mae, \"MSE\": mse, \"R²\": r2}\n",
        "    trained_models[model_name] = model\n",
        "\n",
        "    #grid = sns.relplot(x=y_test, y=y_pred)\n",
        "    # grid.set(\n",
        "    #   title = model_name + \": Predicted vs. Observed Final Scores\",\n",
        "    #    xlable = \"Observed Fina; Scores (test data)\",\n",
        "    #   ylable = \"Predicted Final Scores\"\n",
        "    # )\n",
        "    #grid.set_titles(model_name + \": Predicted vs. Observed Final Scores\")\n",
        "    #grid.set_axis_labels(\"Observed Fina; Scores (test data)\", \"Predicted Final Scores\")\n",
        "    #grid.ax.axline((0,0),slope = 1, color = 'k', ls = '--')\n",
        "    visualize_predictions(y_test, y_pred, model_name)\n",
        "\n",
        "  return result, trained_models\n",
        "\n",
        "def visualize_predictions(y_test, y_pred, model_name):\n",
        "  \"\"\"\n",
        "  This function generates a scatter plot comparing actual vs. predicted final scores.\n",
        "  With parameters:\n",
        "  y_test(Series): Actual final scores.\n",
        "  y_pred(array): Predicted final scores.\n",
        "  model_name(str): Name of the model used for prediction.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize = (8, 6))\n",
        "  sns.scatterplot(x=y_test, y=y_pred, alpha = 0.7)\n",
        "  plt.xlabel(\"Observed Final Score\")\n",
        "  plt.ylabel(\"Predicted Final Score\")\n",
        "  plt.title(model_name + \": Observed vs. Predicted Final Scores\")\n",
        "  plt.axline((0,0), slope = 1, color = \"black\", linestyle = \"--\")\n",
        "  plt.show()\n",
        "\n",
        "def feature_importance_analysis(model, X_train):\n",
        "  \"\"\"\n",
        "  This function analyzes and visualizes feature importance for the Random Foret model.\n",
        "  With parameters:\n",
        "  model(RandomForestRegressor): Trained Random Forest model\n",
        "  X_train(DataFrame): Training feature set.\n",
        "  \"\"\"\n",
        "  if isinstance(model, RandomForestRegressor):\n",
        "    importance = model.feature_importances_\n",
        "    feature_names = X_train.columns\n",
        "\n",
        "    plt.figure(figsize = (8,6))\n",
        "    sns.barplot(x=importance, y=feature_names)\n",
        "    plt.xlabel(\"Feature Importance Score\")\n",
        "    plt.ylabel(\"Features\")\n",
        "    plt.title(\"Feature Importance in Predicting Final Grades\")\n",
        "    plt.show()\n",
        "\n",
        "#training models after dataset processing\n",
        "df1, df2, df3 = load_and_clean_data()\n",
        "df1, df2, df3 = process_study_time(df1, df2, df3)\n",
        "merged_df = merge_datasets(df1, df2, df3)\n",
        "filtered_df = filter_study_time_groups(merged_df)\n",
        "X_train, X_test, y_train, y_test = preprocess_data(filtered_df)\n",
        "results, trained_models = train_and_evaluate_models(X_train, X_test, y_train, y_test)\n",
        "\n",
        "#print results\n",
        "for model, metrics in results.items():\n",
        "  print(model +\" Performance:\")\n",
        "  for metric, value in metrics.items():\n",
        "    print(metric +  \" = \" + str(round(value, 4)))\n",
        "  print()\n",
        "\n",
        "#Analyze feature importance (only for Random Forest)\n",
        "feature_importance_analysis(trained_models[\"Random Forest\"], X_train)\n",
        "\n",
        "#Visualize the Disision Tree\n",
        "#plt.figure(dpi = 300)\n",
        "#plot_tree(\n",
        "    #models[\"Decision Tree\"],\n",
        "    #feature_names = X_train.columns,\n",
        "    #filled = True,\n",
        "    #impurity = False,\n",
        "    #proportion = True,\n",
        "    #rounded = True,\n",
        "    #max_depth = 2,\n",
        "    #fontsize = 5\n",
        "#)\n",
        "#plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Y1GIXsf4c2nD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "748cdfd8-a347-4497-8275-32fb5e7cc946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/CSE163_project/Student_performance_data_.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-08b3f5cac4e9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;31m#training models after dataset processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_clean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_study_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-08b3f5cac4e9>\u001b[0m in \u001b[0;36mload_and_clean_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mReturns\u001b[0m \u001b[0mthree\u001b[0m \u001b[0mcleaned\u001b[0m \u001b[0mDataFrames\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfurther\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \"\"\"\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/CSE163_project/Student_performance_data_.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/CSE163_project/StudentsPerformance_with_headers.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Student performance data/DATA.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/CSE163_project/Student_performance_data_.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BqA6Zh5q0tdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "HzNmRrT-rU01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5NF4ZuWRPYLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df"
      ],
      "metadata": {
        "id": "dy-8jZ6qcpZC",
        "outputId": "bfe203ea-b64b-4883-d8de-4a18533e562f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'filter_study_time_groups' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-91fb32d53a24>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiltered_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_study_time_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filter_study_time_groups' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J81KpGynNenk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}